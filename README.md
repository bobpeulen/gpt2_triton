# ** Deploying GPT2 on NVIDIA Triton Inference Server using OCI Data Science**

## Files:
- Dockerfile --> To build NVIDIA Triton Inference server
- entrypoint.sh --> Entrypoint for docker
- Notebook --> All steps to download GPT2, build model artifacts, build and push docker image to OCIR, and store and deploy GPT2 on image
